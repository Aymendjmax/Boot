import os
import telebot
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
from threading import Thread, Lock
from flask import Flask
import time
import logging
import re

# ... (Ø§Ø¨Ù‚Ù‰ Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³Ø¬Ù„ ÙˆØªÙ‡ÙŠØ¦Ø© Flask ÙƒÙ…Ø§ Ù‡ÙŠ)

# Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
SEARCH_SOURCES = {
    "Ø§Ù„Ø¯Ø±ÙˆØ³": "https://www.eddirasa.com/?s=",
    "Ø§Ù„ÙØ±ÙˆØ¶": "https://www.dzexams.com/search?q="
}

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙŠÙˆØªÙŠÙˆØ¨
YOUTUBE_API_KEY = os.environ.get('YOUTUBE_API_KEY')  # ÙŠØ­ØªØ§Ø¬ Ù…ÙØªØ§Ø­ YouTube API
YOUTUBE_SEARCH_URL = "https://www.googleapis.com/youtube/v3/search"

def search_youtube(query):
    try:
        params = {
            'part': 'snippet',
            'q': query + " Ù…Ù†Ù‡Ø§Ø¬ Ø§Ù„Ø¬Ø²Ø§Ø¦Ø± Ø±Ø§Ø¨Ø¹Ø© Ù…ØªÙˆØ³Ø·",
            'type': 'video',
            'maxResults': 3,
            'order': 'viewCount',  # Ø§Ù„ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª
            'key': YOUTUBE_API_KEY
        }
        
        response = requests.get(YOUTUBE_SEARCH_URL, params=params, timeout=10)
        results = []
        
        for item in response.json().get('items', []):
            video_id = item['id']['videoId']
            title = item['snippet']['title']
            url = f"https://youtu.be/{video_id}"
            results.append(f"{title}\n{url}")
        
        return results if results else None
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ø­Ø« ÙŠÙˆØªÙŠÙˆØ¨: {str(e)}")
        return None

def search_websites(query):
    results = []
    for source_name, url in SEARCH_SOURCES.items():
        try:
            search_url = url + quote(query)
            response = requests.get(search_url, timeout=5)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            links = []
            for link in soup.find_all('a', href=True):
                if re.search(r'(Ø¯Ø±Ø³|Ù…Ù„Ø®Øµ|ØªÙ…Ø±ÙŠÙ†|ÙØ±Ø¶|Ø§Ø®ØªØ¨Ø§Ø±)', link.text, re.IGNORECASE):
                    links.append(f"{link.text.strip()}\n{link['href']}")
                    if len(links) >= 2:
                        break
            
            if links:
                results.append(f"ğŸ” Ù†ØªØ§Ø¦Ø¬ Ù…Ù† {source_name}:\n" + "\n".join(links))
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¨Ù…ÙˆÙ‚Ø¹ {source_name}: {str(e)}")
    
    return results if results else None

@bot.message_handler(func=lambda message: True)
def handle_all_messages(message):
    try:
        text = message.text.lower()
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ ÙˆØ§Ù„ØªØ¹Ø±ÙŠÙ (Ø§Ø¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„
        website_results = search_websites(text)
        youtube_results = search_youtube(text)
        
        response = []
        
        if website_results:
            response.extend(website_results)
            
        if youtube_results:
            response.append("ğŸ¬ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù‚ØªØ±Ø­Ø©:\n" + "\n".join(youtube_results))
            
        if not response:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini ÙƒØ­Ù„ Ø£Ø®ÙŠØ±
            gemini_response = ask_gemini(text)
            response.append(gemini_response)
            
        bot.reply_to(message, "\n\n".join(response) if response else "Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ØŒ Ø­Ø§ÙˆÙ„ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø¢Ø®Ø±")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {str(e)}")
        bot.reply_to(message, "Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.")

# ... (Ø§Ø¨Ù‚Ù‰ Ø¹Ù„Ù‰ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¯ÙˆØ§Ù„ ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„ ÙƒÙ…Ø§ Ù‡ÙŠ)
